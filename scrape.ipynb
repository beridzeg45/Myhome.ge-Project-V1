{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime as dt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns=200\n",
    "\n",
    "\n",
    "path=r\"C:\\Users\\berid\\python\\myhome project\"\n",
    "\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "\n",
    "\n",
    "from selenium.webdriver.edge.options import Options\n",
    "\n",
    "edge_options = Options()\n",
    "edge_options.add_argument('--headless')\n",
    "edge_options.add_argument(\"--blink-settings=imagesEnabled=false\")  # Disable images\n",
    "edge_options.add_argument(\"--autoplay-policy=no-user-gesture-required\")  # Disable autoplay\n",
    "edge_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Edge(options=edge_options)\n",
    "driver.maximize_window()\n",
    "driver.execute_script(\"document.body.style.zoom='25%'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'201024'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "today=datetime.datetime.today().strftime('%d%m%y')\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page : 6, Len : 100\r"
     ]
    }
   ],
   "source": [
    "all_urls=[]\n",
    "\n",
    "\n",
    "if not any([today in file for file in os.listdir(os.path.join(path,'urls'))]):\n",
    "    for page in range(1,21):\n",
    "        try:\n",
    "            url=f\"https://www.myhome.ge/s/iyideba-bina-Tbilisshi/?deal_types=1&real_estate_types=1&cities=1&currency_id=1&CardView=2&page={page}&slug=iyideba-bina-Tbilisshi\"\n",
    "            driver.get(url)\n",
    "\n",
    "            hrefs=WebDriverWait(driver,10).until(expected_conditions.visibility_of_all_elements_located((By.CSS_SELECTOR,'div[class=\"relative flex w-full space-x-5\"] a')))\n",
    "            for href in hrefs:\n",
    "                try:\n",
    "                    url=href.get_attribute('href')\n",
    "                    all_urls.append(url)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            print(f'Page : {page}, Len : {len(all_urls)}', end='\\r')\n",
    "        \n",
    "        except:\n",
    "            pickle.dump(all_urls,open(os.path.join(path,'urls',f'urls_{today}.pickle'),'wb'))\n",
    "\n",
    "    pickle.dump(all_urls,open(os.path.join(path,'urls',f'urls_{today}.pickle'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7284"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urls=[]\n",
    "for file in os.listdir(os.path.join(path,'urls')):\n",
    "    if file.endswith('pickle'):\n",
    "        file_path=os.path.join(path,'urls',file)\n",
    "        data=pickle.load(open(file_path,'rb'))\n",
    "        all_urls.extend(data)\n",
    "        \n",
    "all_urls=list(set(all_urls))\n",
    "len(all_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Data And Saving in SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dict(url,scrape_data):\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        address=driver.find_element(By.CSS_SELECTOR,'div[class=\"flex flex-wrap items-center justify-between lg:flex-nowrap\"]').text\n",
    "    except:\n",
    "        address=None\n",
    "\n",
    "    try:\n",
    "        street=driver.find_element(By.CSS_SELECTOR,'div[class=\"px-0 pt-0 pb-4 mt-5 bg-white md:border md:border-gray-20 rounded-2xl md:px-6 md:pt-5 md:pb-6\"] div[class=\"flex flex-col items-start\"]').text\n",
    "    except:\n",
    "        street=None    \n",
    "        \n",
    "    try:\n",
    "        details=driver.find_element(By.CSS_SELECTOR,'div[class=\"items-center flex-wrap border border-gray-20 rounded-xl p-5 md:p-6 lg:p-8 mt-0 md:mt-4 justify-between grid grid-cols-2 md:grid-cols-4 gap-3\"]').text\n",
    "    except:\n",
    "        details=None\n",
    "\n",
    "    try:\n",
    "        price=driver.find_element(By.CSS_SELECTOR,'div[class=\"col-span-3 hidden lg:block sticky\"] div[class=\"flex items-center justify-start md:justify-between\"]').text\n",
    "    except:    \n",
    "        price=None\n",
    "\n",
    "    try:\n",
    "        see_more_button=driver.find_element(By.CSS_SELECTOR,'button[class=\"text-primary-100 text-sm flex items-center gap-2 mt-4 hidden lg:flex\"]')\n",
    "        driver.execute_script('arguments[0].click();',see_more_button)\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        parameters = {i.text.split('\\n')[0]: i.text.split('\\n')[1] for i in [i for i in driver.find_elements(By.CSS_SELECTOR, 'div[class=\"py-5 pl-5 pr-8 mt-4 bg-white border rounded-2xl md:py-6 md:pl-6 border-gray-20 md:mt-5\"]') if 'დამატებითი პარამეტრები' in i.text][0]\n",
    "                            .find_elements(By.CSS_SELECTOR, 'div[class=\"flex text-sm \"]')}\n",
    "    except:\n",
    "        parameters=None\n",
    "\n",
    "    try:\n",
    "        furniture=[i for i in driver.find_elements(By.CSS_SELECTOR,'div[class=\"py-5 pl-5 pr-8 mt-4 bg-white border rounded-2xl md:py-6 md:pl-6 border-gray-20 md:mt-5\"]') if \"ავეჯი\" in i.text][0].text\n",
    "    except:\n",
    "        furniture=None\n",
    "\n",
    "    dict={'URL':url,'Address':address,'Street':street,'Details':details,'Price':price,'Parameters':parameters,'Furniture':furniture,'Scrape Date':scrape_data}\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.Connection(\"myhome.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Step 1: Create a new table with the desired column order\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS homes (\n",
    "    URL TEXT,\n",
    "    ADDRESS TEXT,\n",
    "    STREET TEXT,\n",
    "    DETAILS TEXT,\n",
    "    PRICE TEXT,\n",
    "    PARAMETERS TEXT,\n",
    "    FURNITURE TEXT,\n",
    "    SCRAPE_DATE TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "conn.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped : 7333, Left : 8\n"
     ]
    }
   ],
   "source": [
    "screped_urls=pd.read_sql_query('SELECT DISTINCT URL FROM homes ',conn)['URL'].tolist()#WHERE ADDRESS != \"None\"\n",
    "\n",
    "urls_to_scrape=[url for url in all_urls if url not in screped_urls]\n",
    "\n",
    "print(f'Scraped : {len(screped_urls)}, Left : {len(urls_to_scrape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 / 63, : {'URL': 'https://www.myhome.ge/pr/19499623/iyideba-5-otaxiani-bina-vakeshi/', 'Address': 'იყიდება 5 ოთახიანი ბინა ვაკეში\\nგუშინ 21:53-ზე\\n51\\nID: 19499623', 'Street': 'ყიფშიძე ნ. ქ. 10', 'Details': 'საერთო ფართი\\n167 მ²\\nოთახი\\n5\\nსაძინებელი\\n3\\nსართული\\n12 / 13', 'Price': '638,190\\n₾', 'Parameters': {'სტატუსი': 'მშენებარე', 'სვ.წერტილები': '2', 'მდგომარეობა': 'მწვანე კარკასი', 'პროექტის ტიპი': 'არასტანდარტული', 'ჭერის სიმაღლე': '4 მ'}, 'Furniture': None, 'Scrape Date': '20-10-24'}: '2.85 მ', 'გათბობა': 'ცენტრალური გათბობა', 'პარკირება': 'ეზოს პარკინგი', 'ცხელი წყალი': 'ცენტრალური გათბობა', 'სამშენებლო მასალა': 'კომბინირებული', 'აივანი': '1/3.8 მ²', 'მისაღები': 'გამოყოფილი/31 მ²', 'სათავსო': 'საკუჭნაო', 'ინტერნეტი': 'კი', 'ტელევიზია': 'კი', 'ბუნ. აირი': 'კი', 'ლიფტი': 'კი', 'წყალი': 'კი', 'კანალიზაცია': 'კი', 'ელ.ენერგია': 'კი', 'ტელეფონი': 'კი', 'სამზარეულო + ტექნიკა': 'კი'}, 'Furniture': 'ავეჯი\\nავეჯი\\nმაგიდა\\nსკამები\\nქურა (გაზის/ელექტრო)\\nღუმელი\\nსარეცხი მანქანა', 'Scrape Date': '20-10-24'}ნი\\nმაგიდა\\nსკამები\\nქურა (გაზის/ელექტრო)\\nღუმელი\\nკონდინციონერი\\nმაცივარი\\nსარეცხი მანქანა', 'Scrape Date': '20-10-24'}\r"
     ]
    }
   ],
   "source": [
    "today=datetime.datetime.today().strftime('%d-%m-%y')\n",
    "\n",
    "for i,url in enumerate(urls_to_scrape,start=1):\n",
    "    if url in screped_urls:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        dict=return_dict(url,today)\n",
    "        values=[str(v) for k, v in dict.items()]\n",
    "        cursor.execute(\"INSERT INTO homes (URL, ADDRESS, STREET, DETAILS, PRICE, PARAMETERS, FURNITURE, SCRAPE_DATE) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\", values)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f'{e}')\n",
    "    \n",
    "    print(f'{i} / {len(urls_to_scrape)}, : {dict}',end='\\r')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
